{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0abadc-abb1-4983-89f2-2690f4a13b3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "INSTALL ALBUMENTATIONS (TIVE QUE USAR ESSES ARGUMENTOS POR JÁ TER OPENCV INSTALADO NO SISTEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df285c47-113e-48ce-a42a-622290a25ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U albumentations --no-binary qudida,albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef0e55-f5a0-458a-9974-7283f7141758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import csv\n",
    "import random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "import os \n",
    "import json \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f16e1-d075-4a1a-be8f-b63222cac034",
   "metadata": {},
   "source": [
    "\n",
    "OPEN CSV COM ANOTAÇÕES DE BOUNDING BOXES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff081777-02d7-4bf7-abad-e869f2630938",
   "metadata": {},
   "outputs": [],
   "source": [
    "images    = []\n",
    "trainRows = []\n",
    "allRows   = []\n",
    "\n",
    "with open('/content/drive/MyDrive/CSVs/Modelo5.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        \n",
    "        allRows.append(row)\n",
    "        checkTrain = row[0]\n",
    "\n",
    "        if checkTrain == 'TRAIN':\n",
    "            trainRows.append(row)\n",
    "\n",
    "        if not images:\n",
    "            if checkTrain == 'TRAIN':\n",
    "                images.append(row[1])\n",
    "\n",
    "        elif row[1] != images[-1] and checkTrain == 'TRAIN':\n",
    "            images.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d077e5-8960-4570-84c4-7cf5d27d8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(labels,img,show = False):\n",
    "    \n",
    "    labels = np.array(labels).astype(int) \n",
    "    img = np.array(img).astype(np.uint8)  \n",
    "    h,w,c  = img.shape\n",
    "    for bb in labels:\n",
    "        if max(bb)<=1:\n",
    "            y = (bb[[1,3,5,7]]*h).astype(int)\n",
    "            x = (bb[[0,2,4,6]]*w).astype(int)\n",
    "            cv2.rectangle(img,(x[0],y[0]),(x[1],y[2]),(0,255,0),2)\n",
    "        #if bb.shape[0] == 4:\n",
    "        #    bb_int = bb.astype(int)\n",
    "        #    cv2.rectangle(img,(bb_int[0],bb_int[1]),(bb_int[2],bb_int[3]),(0,255,0),2)\n",
    "        else:\n",
    "            y = (bb[[1,3]]).astype(int)\n",
    "            x = (bb[[0,2]]).astype(int)\n",
    "            cv2.rectangle(img,(x[0],y[0]),(x[1],y[1]),(0,255,0),2)\n",
    "        \n",
    "    if show:\n",
    "        plt.figure(figsize = (15,30))\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e9923-fab6-4a99-bb4e-4afcb7f9137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_json(path):\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_labelme(data,img):\n",
    "    h,w,c = img.shape\n",
    "    points = []\n",
    "    \n",
    "    def clip(value,top):\n",
    "        return min(max(value,0),top)\n",
    "    \n",
    "    for shapes in data[\"shapes\"]:\n",
    "        x0,y0 = np.array(shapes[\"points\"])[0]\n",
    "        x1,y1 = np.array(shapes[\"points\"])[1]\n",
    "\n",
    "        if x0>x1:\n",
    "            x1,x0 = x0,x1 \n",
    "\n",
    "        if y0>y1:\n",
    "            y1,y0 = y0,y1 \n",
    "            \n",
    "        if x1 == x0 or y1 == y0:\n",
    "            continue\n",
    "\n",
    "        x1,x0,y1,y0 = clip(x1,w), clip(x0,w), clip(y1,h), clip(y0,h)\n",
    "        points.append([int(x0), int(y0), int(x1), int(y1)])\n",
    "    \n",
    "    return np.array(points)\n",
    "\n",
    "def labelme_to_tf(data,img):\n",
    "    h,w,c = img.shape\n",
    "    points = []\n",
    "    \n",
    "    def clip(value):\n",
    "        return min(max(value,0),1)\n",
    "    \n",
    "    for shapes in data[\"shapes\"]:\n",
    "        x0,y0 = np.array(shapes[\"points\"])[0]\n",
    "        x1,y1 = np.array(shapes[\"points\"])[1]\n",
    "        \n",
    "        if x0>x1:\n",
    "            x1,x0 = x0,x1 \n",
    "        \n",
    "        if y0>y1:\n",
    "            y1,y0 = y0,y1 \n",
    "        \n",
    "        x1,x0,y1,y0 = clip(x1),clip(x0),clip(y1),clip(y0)\n",
    "        \n",
    "        if x1 == x0 or y1 == y0:\n",
    "            continue\n",
    "\n",
    "        points.append([x0/w, y0/h,  x1/w, y0/h, x1/w, y1/h, x0/w, y1/h])\n",
    "       \n",
    "    \n",
    "    return np.array(points)\n",
    "    \n",
    "    \n",
    "def proportion_to_pixel(img,labels):\n",
    "    h,w,c  = img.shape\n",
    "    bb = []\n",
    "    for proportional_bb in labels:\n",
    "        #pix_bb = proportional_bb.copy()\n",
    "        \n",
    "        y = (proportional_bb[[1,3,5,7]]*h).astype(int)\n",
    "        x = (proportional_bb[[0,2,4,6]]*w).astype(int)\n",
    "        x_min, y_min, x_max, y_max = x[0],y[0],x[1],y[2]\n",
    "        \n",
    "        bb+=[[x_min, y_min, x_max, y_max]]\n",
    "        \n",
    "    return np.array(bb)\n",
    "        \n",
    "def pixel_to_proportion(img,labels):\n",
    "    h,w,c  = img.shape\n",
    "    bb = []\n",
    "    for proportional_bb in labels:\n",
    "        \n",
    "        #pix_bb = proportional_bb.copy()\n",
    "        #print(\"H\",h,\"W\",w,\"proportional_bb\",proportional_bb)\n",
    "        \n",
    "        y = proportional_bb.astype(np.float32)[[0,2]]/h\n",
    "        \n",
    "        x = proportional_bb.astype(np.float32)[[0,2]]/w\n",
    "        \n",
    "\n",
    "        \n",
    "        #print(x,y)\n",
    "        \n",
    "        x_min, y_min, x_max, y_max = x[0],y[0],x[1],y[1]\n",
    "        \n",
    "        if x_min == x_max or y_max == y_min:\n",
    "            continue\n",
    "        \n",
    "        bb+=[[x_min, y_min, x_max, y_max]]\n",
    "        \n",
    "    return np.array(bb)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be580f3-cafa-4a30-bbc0-c45d1faafda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"realCampo/\"\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "k=0 \n",
    "for file in files:\n",
    "    k+=1\n",
    "    if \".json\" in file:\n",
    "        \n",
    "        img    = cv2.imread(folder_path+file.replace(\".json\",\".jpg\"))[:,:,::-1]\n",
    "        data   = read_json(folder_path+file)\n",
    "        labels = labelme_to_tf(data,img)\n",
    "        bboxes = proportion_to_pixel(img,labels)\n",
    "        draw_labels(bboxes,img)\n",
    "        \n",
    "        break\n",
    "        \n",
    "img    = cv2.imread(\"realCampo/6.jpg\")[:,:,::-1]\n",
    "data   = read_json(\"realCampo/6.json\")\n",
    "labels = parse_labelme(data,img)\n",
    "bboxes = pixel_to_proportion(img,labels)\n",
    "\n",
    "img_drawn = draw_labels(labels,img,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4e361-311e-4d1c-9009-add21ebfe22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lass Change:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_transform = A.Compose([\n",
    "\n",
    "        A.OneOf([\n",
    "            \n",
    "            A.Blur(blur_limit=20, p=0.99),\n",
    "            \n",
    "            A.Spatter(mean=0.65, \n",
    "                          std=0.5, \n",
    "                          gauss_sigma=2, \n",
    "                          cutout_threshold=0.68, \n",
    "                          intensity=0.6, \n",
    "                          mode='rain', \n",
    "                          always_apply=True, \n",
    "                          p=0.99)\n",
    "\n",
    "            ], p=1)\n",
    "\n",
    "        ],bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "    def apply(self,img,bboxes):\n",
    "        \n",
    "        return self.input_transform(image=img, bboxes=bboxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9498a1b-f745-414d-bba3-ef889a789a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "change      = Change()  \n",
    "transformed = change.apply(img,bboxes)\n",
    "    \n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(transformed[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46169e15-7b85-49c7-b454-21cebc43ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.noise_transform = A.Compose([\n",
    "\n",
    "        A.OneOf([\n",
    "\n",
    "\n",
    "            #A.ImageCompression (quality_lower=65, quality_upper=75, always_apply=False, p=0.99), \n",
    "\n",
    "            #A.ISONoise(color_shift=(0.2, 0.3), intensity=(0.1, 0.2), always_apply=False, p=0.99), \n",
    "\n",
    "            #A.MultiplicativeNoise (multiplier=(0.7, 1.3), per_channel=True, elementwise=False, always_apply=True, p=0.99),\n",
    "\n",
    "            A.Sharpen(alpha=(0.2, 0.25), lightness=(2, 4), always_apply=True, p=0.99),\n",
    "            \n",
    "            A.RGBShift(r_shift_limit=130, g_shift_limit=130, b_shift_limit=130, always_apply=True, p=0.99)\n",
    "\n",
    "            ], p=1)\n",
    "\n",
    "        ],bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "        \n",
    "    def apply(self,img,bboxes):\n",
    "        \n",
    "        return self.noise_transform(image=img, bboxes=bboxes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a1434-c881-4046-b4ca-eea188180367",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise       = Noise()\n",
    "transformed = noise.apply(img,bboxes)\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(transformed[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc917d4-d537-46c1-8485-a95af4176e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.color_transform = A.Compose([\n",
    "\n",
    "        A.OneOf([\n",
    "\n",
    "\n",
    "            #A.HueSaturationValue (hue_shift_limit=130, sat_shift_limit=140, val_shift_limit=30, always_apply=False, p=0.99),\n",
    "\n",
    "            #A.RandomBrightnessContrast (brightness_limit=0.3, contrast_limit=0.05, brightness_by_max=True, always_apply=True, p=0.99)\n",
    "\n",
    "            A.RandomGamma (gamma_limit=(170, 280), eps=None, always_apply=True, p=0.99)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            ], p=1)\n",
    "\n",
    "        ],bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "\n",
    "    def apply(self,img,bboxes):\n",
    "        \n",
    "        return self.color_transform(image=img, bboxes=bboxes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b11e7-ed39-4268-beaf-425af4e3bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = Color()\n",
    "\n",
    "transformed = color.apply(img,bboxes)\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(transformed[\"image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200f959-8de6-49a4-a29a-7b248f527d88",
   "metadata": {},
   "source": [
    "[1/i for i in range(2,6)]\n",
    "4 rotações (original + 3)\n",
    "4 crops (original + 3)\n",
    "3 transformações (original mais 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44385d5-1a5e-405f-a821-bb72ab3d0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crop:\n",
    "    def __init__(self,crop_proportions = None):\n",
    "        self.iters = 0\n",
    "        \n",
    "        if crop_proportions is None:\n",
    "            self.crop_proportions     = [1/i for i in range(2,6)]\n",
    "            self.crop_proportions_4k  = [0.1, 0.15, 0.2, 0.24, 0.5]\n",
    "            #[i for i in np.linspace( 0.1,0.8,6)]\n",
    "            \n",
    "    def apply(self,img,bboxes,previous_transforms):\n",
    "        h,w,c  = img.shape\n",
    "        self.crops = {}\n",
    "        \n",
    "        if h > 2000 and w > 2000:\n",
    "            \n",
    "            for proportion in self.crop_proportions_4k :\n",
    "                \n",
    "                visibility = 1 if proportion < 0.22 else 0.94 \n",
    "                \n",
    "                self.crops[str(round(proportion,3))] = A.Compose([\n",
    "                    A.RandomCrop(width=int(w*proportion), height=int(h*proportion))\n",
    "                ],bbox_params = A.BboxParams(format='pascal_voc', min_visibility=visibility, label_fields=[]))\n",
    "        else:  \n",
    "            for proportion in self.crop_proportions:\n",
    "                \n",
    "                visibility = 1 if proportion < 0.22 else 0.94 \n",
    "                \n",
    "                self.crops[str(round(proportion,3))] = A.Compose([\n",
    "                    A.RandomCrop(width=int(w*proportion), height=int(h*proportion))\n",
    "                ],bbox_params = A.BboxParams(format='pascal_voc', min_visibility=visibility, label_fields=[]))\n",
    "        \n",
    "        \n",
    "        transformations = {}\n",
    "        \n",
    "        for proportion,crop in self.crops.items():\n",
    "\n",
    "            croped = crop(image=img, bboxes=bboxes)\n",
    "            \n",
    "            \n",
    "            tries = 0\n",
    "            while len(croped[\"bboxes\"])<3 and tries <= 200:\n",
    "                croped = crop(image=img, bboxes=bboxes)\n",
    "                tries+=1\n",
    "                #print(len(croped[\"bboxes\"]),\"tries \",tries)\n",
    "            \n",
    "            if tries==201:\n",
    "                print(\"crop tries exceed 200\")\n",
    "                continue\n",
    "            #print(len(croped[\"bboxes\"]))\n",
    "                \n",
    "            transformations[previous_transforms+\"+crop:v\"+str(self.iters)+\"-p\"+str(proportion)] = {\"image\":croped[\"image\"],\"bboxes\":croped[\"bboxes\"]}\n",
    "                \n",
    "            self.iters+=1\n",
    "            \n",
    "        return transformations\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50474e21-273f-45c4-9ae3-8ee96a054757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rotations:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.vertical = A.Compose([\n",
    "\n",
    "            A.VerticalFlip(p=1)\n",
    "\n",
    "        ],bbox_params = A.BboxParams(format='pascal_voc', min_visibility=0.87, label_fields=[]))\n",
    "\n",
    "        self.horizontal = A.Compose([\n",
    "\n",
    "            A.HorizontalFlip(p=1)\n",
    "\n",
    "        ],bbox_params = A.BboxParams(format='pascal_voc', min_visibility=0.87, label_fields=[]))\n",
    "\n",
    "\n",
    "        self.vertical_horizontal = A.Compose([\n",
    "\n",
    "            A.VerticalFlip(p=1),\n",
    "            A.HorizontalFlip(p=1)\n",
    "\n",
    "        ],bbox_params = A.BboxParams(format='pascal_voc', min_visibility=0.87, label_fields=[]))\n",
    "\n",
    "    def apply(self,img,bboxes,root):\n",
    "        \n",
    "        transformations = {}\n",
    "        \n",
    "        print(\"TOTAL LABELS:\",np.array(bboxes).shape)\n",
    "        \n",
    "        transformations[root+\"_RAW\"] = {\"image\":img.copy(),\"bboxes\":np.array(bboxes).astype(int).tolist()}\n",
    "        \n",
    "        #vertical_fliped    = self.vertical(image=img, bboxes=bboxes)\n",
    "        #transformations[root+\"_vertical_fliped\"] = {\"image\":vertical_fliped[\"image\"],\"bboxes\":np.array(vertical_fliped[\"bboxes\"]).astype(int).tolist()}\n",
    "        \n",
    "        #vertical_fliped    = self.horizontal(image=img, bboxes=bboxes)\n",
    "        #transformations[root+\"_horizontal_fliped\"] = {\"image\":vertical_fliped[\"image\"], \"bboxes\":np.array(vertical_fliped[\"bboxes\"]).astype(int).tolist()}\n",
    "        \n",
    "        vertical_fliped    = self.vertical_horizontal(image=img, bboxes=bboxes)\n",
    "        transformations[root+\"_vertical_horizontal_fliped\"] = {\"image\":vertical_fliped[\"image\"],\"bboxes\":np.array(vertical_fliped[\"bboxes\"]).astype(int).tolist()}\n",
    "        \n",
    "        return transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bca3d-8fa1-4807-843a-772cee9ec4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img    = cv2.imread(\"realCampo/8.jpg\")[:,:,::-1]\n",
    "data   = read_json(\"realCampo/8.json\")\n",
    "labels = parse_labelme(data,img)\n",
    "bboxes = pixel_to_proportion(img,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039e049-2f73-4850-a6d4-c1ec48120a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root   = \"realCampo/8.json\"\n",
    "img    = cv2.imread(\"realCampo/8.jpg\")[:,:,::-1]\n",
    "data   = read_json(\"realCampo/8.json\")\n",
    "labels = parse_labelme(data,img)\n",
    "bboxes = pixel_to_proportion(img,labels)\n",
    "\n",
    "img           = draw_labels(labels,img,True)\n",
    "augmentations = {}\n",
    "rotations     = Rotations()\n",
    "crop          = Crop()\n",
    "rotated       = rotations.apply(img,labels,root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77248536-2210-48c5-a2f6-215935d48283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img    = cv2.imread(\"realCampo/2.jpg\")[:,:,::-1]\n",
    "#data   = read_json(\"realCampo/2.json\")\n",
    "#labels = labelme_to_tf(data,img)\n",
    "#bboxes = proportion_to_pixel(img,labels)\n",
    "\n",
    "#img    = cv2.imread(\"CENIBRA/IMG_6272.JPG\")[:,:,::-1]\n",
    "#data   = read_json(\"CENIBRA/IMG_6272.json\")\n",
    "\n",
    "#img    = cv2.imread(\"CENIBRA/IMG_6338.JPG\")[:,:,::-1]\n",
    "#data   = read_json(\"CENIBRA/IMG_6338.json\")\n",
    "\n",
    "root   = \"Eucalipto/6.json\"\n",
    "\n",
    "img    = cv2.imread(\"Eucalipto/6.jpg\")[:,:,::-1]\n",
    "data   = read_json(\"Eucalipto/6.json\")\n",
    "\n",
    "labels = parse_labelme(data,img)\n",
    "bboxes = pixel_to_proportion(img,labels)\n",
    "\n",
    "\n",
    "augmentations = {}\n",
    "rotations     = Rotations()\n",
    "crop          = Crop()\n",
    "rotated       = rotations.apply(img,labels,root)\n",
    "augmentations.update(rotated)\n",
    "\n",
    "\n",
    "for key in rotated:   \n",
    "    crop_transforms = crop.apply(rotated[key][\"image\"],rotated[key][\"bboxes\"],key)\n",
    "    augmentations.update(crop_transforms)\n",
    "    \n",
    "augmentations.update(rotated) \n",
    "\n",
    "color = Color()\n",
    "\n",
    "keys = list(augmentations.keys())\n",
    "\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    \n",
    "    transformed_color  = color.apply(augmentations[key][\"image\"],augmentations[key][\"bboxes\"])\n",
    "    transformed_change = change.apply(augmentations[key][\"image\"],augmentations[key][\"bboxes\"])\n",
    "    transformed_noise  = noise.apply(augmentations[key][\"image\"],augmentations[key][\"bboxes\"])\n",
    "    \n",
    "    augmentations[key+\"+color\"]  = transformed_color\n",
    "    augmentations[key+\"+change\"] = transformed_change\n",
    "    augmentations[key+\"+noise\"]  = transformed_noise\n",
    "    \n",
    "    \n",
    "    f, axarr = plt.subplots(1,4,figsize=(32,14))\n",
    "    axarr[0].axis('off')\n",
    "    axarr[1].axis('off')\n",
    "    axarr[2].axis('off')\n",
    "    axarr[3].axis('off')\n",
    "    \n",
    "    axarr[0].set_title(key)\n",
    "    axarr[1].set_title(key+\"_Color\")\n",
    "    axarr[2].set_title(key+\"_Change\")\n",
    "    axarr[3].set_title(key+\"_Noise\")\n",
    "    \n",
    "    print(augmentations[key][\"image\"].shape)\n",
    "    print(transformed_color[\"image\"].shape)\n",
    "    print( transformed_change[\"image\"].shape)\n",
    "    print(transformed_noise[\"image\"].shape)\n",
    "    \n",
    "    draw_labels(augmentations[key][\"bboxes\"],  augmentations[key][\"image\"])\n",
    "    draw_labels(transformed_color[\"bboxes\"],   transformed_color[\"image\"])\n",
    "    draw_labels(transformed_change[\"bboxes\"],  transformed_change[\"image\"])\n",
    "    draw_labels(transformed_noise[\"bboxes\"],   transformed_noise[\"image\"])\n",
    "    \n",
    "    #axarr[0].imshow(draw_labels(augmentations[key][\"bboxes\"],  augmentations[key][\"image\"]))\n",
    "    #axarr[1].imshow(draw_labels(transformed_color[\"bboxes\"],   transformed_color[\"image\"]) )\n",
    "    #axarr[2].imshow(draw_labels(transformed_change[\"bboxes\"],  transformed_change[\"image\"]))\n",
    "    #axarr[3].imshow(draw_labels(transformed_noise[\"bboxes\"],   transformed_noise[\"image\"]) )\n",
    "    \n",
    "    axarr[0].imshow(draw_labels(augmentations[key][\"bboxes\"],  augmentations[key][\"image\"]))\n",
    "    axarr[1].imshow(transformed_color[\"image\"])\n",
    "    axarr[2].imshow(transformed_change[\"image\"])\n",
    "    axarr[3].imshow(transformed_noise[\"image\"])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e13d8-5901-4190-b08d-013ee99a5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "img     = cv2.imread(\"Eucalipto/6.jpg\")[:,:,::-1]\n",
    "h, w, c = img.shape\n",
    "print(h/w)\n",
    "int(h*0.2) ,int(w*0.2)\n",
    "\n",
    "resized = cv2.resize(img, (int(h*0.2),int(w*0.2)), interpolation = cv2.INTER_AREA)\n",
    "h, w, c = resized.shape\n",
    "\n",
    "print(h/w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a7a0e-5e65-4818-baa3-83e7e28a2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_lite(image,bboxes,image_path):\n",
    "    '''\n",
    "    (x1,y1) ---------------  (x2,y2)\n",
    "      |                         |\n",
    "      |                         |\n",
    "      |                         |\n",
    "      |                         |\n",
    "    (x3,y3) ---------------- (x4,y4)\n",
    "\n",
    "    '''\n",
    "\n",
    "    bboxes  = bboxes\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    tf_bounding_boxes = []\n",
    "    for bb in bboxes:\n",
    "        x_min, y_min, x_max, y_max = bb\n",
    "        \n",
    "        #            \"x1\",        \"x2\",          \"x3\",        \"x4\",\n",
    "        #bb = [float(x_min), float(x_max), float(x_min), float(x_max), \n",
    "        #       \"y1\",              \"y2\",        \"y3\",          \"y4\"\n",
    "        #      float(y_min), float(y_min), float(y_max), float(y_max)]\n",
    "        \n",
    "        \n",
    "         #            \"x1\",        \"y1\",                \"x2\",        \"y1\",\n",
    "        bb = [float(x_min), float(y_min),   float(x_max), float(y_min), \n",
    "        #           \"x2\",       \"y2\",          \"y3\",          \"y4\"\n",
    "              float(x_max), float(y_max),   float(x_min), float(y_max)]\n",
    "\n",
    "        bb = np.array(bb).astype(np.float16)\n",
    "        \n",
    "        bb[[1,3,5,7]] = (bb[[1,3,5,7]]/h).astype(np.float16)\n",
    "        bb[[0,2,4,6]] = (bb[[0,2,4,6]]/w).astype(np.float16)\n",
    "        \n",
    "        \n",
    "        tf_bounding_boxes.append(bb)\n",
    "        \n",
    "        #[\"split\", \"path\", \"log\",\"x1\",\"x2\",\"x3\",\"x4\",\"y1\",\"y2\",\"y3\",\"y4\"]\n",
    "    return np.array(tf_bounding_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21111d7-69fe-4773-9933-22579bd5deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detections(augmentations,transformed_color,key):\n",
    "    f, axarr = plt.subplots(1,4,figsize=(32,14))\n",
    "    axarr[0].axis('off')\n",
    "    axarr[1].axis('off')\n",
    "    axarr[2].axis('off')\n",
    "    axarr[3].axis('off')\n",
    "\n",
    "    axarr[0].set_title(key)\n",
    "    axarr[1].set_title(key+\"_Color\")\n",
    "    axarr[2].set_title(key+\"_Change\")\n",
    "    axarr[3].set_title(key+\"_Noise\")\n",
    "\n",
    "    #draw_labels(augmentations[key][\"bboxes\"],  augmentations[key][\"image\"])\n",
    "    #draw_labels(transformed_color[\"bboxes\"],   transformed_color[\"image\"])\n",
    "    #draw_labels(transformed_change[\"bboxes\"],  transformed_change[\"image\"])\n",
    "    #draw_labels(transformed_noise[\"bboxes\"],   transformed_noise[\"image\"])\n",
    "    #axarr[0].imshow(draw_labels(augmentations[key][\"bboxes\"],  augmentations[key][\"image\"]))\n",
    "    #axarr[1].imshow(draw_labels(transformed_color[\"bboxes\"],   transformed_color[\"image\"]) )\n",
    "    #axarr[2].imshow(draw_labels(transformed_change[\"bboxes\"],  transformed_change[\"image\"]))\n",
    "    #axarr[3].imshow(draw_labels(transformed_noise[\"bboxes\"],   transformed_noise[\"image\"]) )\n",
    "\n",
    "    axarr[0].imshow(draw_labels(augmentations[key][\"bboxes\"],  augmentations[key][\"image\"]))\n",
    "    axarr[1].imshow(draw_labels(transformed_color[\"bboxes\"],   transformed_color[\"image\"]))\n",
    "    axarr[2].imshow(draw_labels(transformed_change[\"bboxes\"],  transformed_change[\"image\"]))\n",
    "    axarr[3].imshow(draw_labels(transformed_noise[\"bboxes\"],   transformed_noise[\"image\"]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5220785-71d6-4608-94c4-0898e0c2d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def AugumentationPipeline(label_paths,show = False):\n",
    "    \n",
    "    image_path = label_paths.replace(\".json\",\".jpg\")\n",
    "    root       = label_paths.replace(\".json\",\"\").replace(\"/\",\"_\")\n",
    "    \n",
    "    img    = cv2.imread(image_path)\n",
    "    data   = read_json(label_paths)\n",
    "    labels = parse_labelme(data,img)\n",
    "    bboxes = pixel_to_proportion(img,labels)\n",
    "\n",
    "    augmentations = {}\n",
    "    rotations     = Rotations()\n",
    "    crop          = Crop()\n",
    "    color         = Color()\n",
    "    change        = Change()\n",
    "    noise         = Noise()\n",
    "    \n",
    "    rotated       = rotations.apply(img,labels,root)\n",
    "    \n",
    "    print(\"applying rotations\")\n",
    "    augmentations.update(rotated)\n",
    "    \n",
    "    print(\"applying crop\")\n",
    "    \n",
    "    for key in tqdm(rotated): \n",
    "        crop_transforms = crop.apply(rotated[key][\"image\"],rotated[key][\"bboxes\"],key)\n",
    "        augmentations.update(crop_transforms)\n",
    "    \n",
    "    keys = list(augmentations.keys())\n",
    "    \n",
    "    print(\"applying change color and noise augumentations\")\n",
    "    \n",
    "    for key in tqdm(keys):\n",
    "        \n",
    "        transformed_color  = color.apply(augmentations[key][\"image\"] ,augmentations[key][\"bboxes\"])\n",
    "        transformed_change = change.apply(augmentations[key][\"image\"],augmentations[key][\"bboxes\"])\n",
    "        transformed_noise  = noise.apply(augmentations[key][\"image\"] ,augmentations[key][\"bboxes\"])\n",
    "\n",
    "        augmentations[key+\"+color\"]  = transformed_color\n",
    "        augmentations[key+\"+change\"] = transformed_change\n",
    "        augmentations[key+\"+noise\"]  = transformed_noise\n",
    "    \n",
    "        if show:\n",
    "            show_detections(augmentations,transformed_color,key)\n",
    "            \n",
    "    save_path = \"augumentations/\"+label_paths.replace(\".json\",\"\").split(\"/\")[0]\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "        \n",
    "    df_dict = {\n",
    "        \"split\": [],\n",
    "        \"path\":  [],\n",
    "        \"log\":   [],\n",
    "        \"x1\":    [],\n",
    "        \"x2\":    [],\n",
    "        \"x3\":    [],\n",
    "        \"x4\":    [],\n",
    "        \"y1\":    [],\n",
    "        \"y2\":    [],\n",
    "        \"y3\":    [],\n",
    "        \"y4\":    []\n",
    "    } \n",
    "    \n",
    "    print(\"saving images and labels\")\n",
    "    \n",
    "    prob = np.random.rand()\n",
    "    \n",
    "    if prob < 0.7:\n",
    "        split = \"TRAIN\"   \n",
    "    elif prob < 0.9:\n",
    "        split = \"TEST\" \n",
    "    else: \n",
    "        split = \"VALIDATION\"\n",
    "    \n",
    "    for key in tqdm(list(augmentations.keys())):\n",
    "        \n",
    "        if len(augmentations[key][\"bboxes\"])>300: \n",
    "            print(\"too many labels in image\",len(augmentations[key][\"bboxes\"]))\n",
    "            continue\n",
    "        \n",
    "        image_path = save_path + \"/\" + key+ \".jpg\"\n",
    "        cv2.imwrite(image_path, augmentations[key][\"image\"])\n",
    "        \n",
    "        h,w,c      = augmentations[key][\"image\"].shape\n",
    "        tf_lite_bb = convert_to_tf_lite(augmentations[key][\"image\"],augmentations[key][\"bboxes\"],image_path)\n",
    "        \n",
    "        for bb in tf_lite_bb:\n",
    "            #print(bb)\n",
    "            df_dict[\"split\"].append(split)\n",
    "            df_dict[\"path\"].append(image_path)\n",
    "            df_dict[\"log\"].append(\"log\") \n",
    "            df_dict[\"x1\"].append(bb[0])  \n",
    "            df_dict[\"x2\"].append(bb[1])   \n",
    "            df_dict[\"x3\"].append(bb[2])   \n",
    "            df_dict[\"x4\"].append(bb[3])   \n",
    "            df_dict[\"y1\"].append(bb[4])   \n",
    "            df_dict[\"y2\"].append(bb[5])   \n",
    "            df_dict[\"y3\"].append(bb[6])   \n",
    "            df_dict[\"y4\"].append(bb[7]) \n",
    "        \n",
    "    return pd.DataFrame(df_dict)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfbc20-11a1-4726-9602-22301186d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from random import shuffle\n",
    "\n",
    "def generate_all_label_paths():\n",
    "    \n",
    "    folders =   ['Eucalipto',\n",
    "                 'oldPinus',\n",
    "                 'CENIBRA',\n",
    "                 'realCampo',\n",
    "                 'Pinus']\n",
    "\n",
    "    label_paths = []\n",
    "\n",
    "    for folder in folders:\n",
    "        files = os.listdir(folder)\n",
    "        for file in files:\n",
    "            if \".json\" in file:\n",
    "                label_paths.append(folder+\"/\"+file)\n",
    "\n",
    "    for label in label_paths:\n",
    "        image_path = label.replace(\".json\",\".jpg\")\n",
    "        \n",
    "    return label_paths\n",
    "\n",
    "labels = generate_all_label_paths()\n",
    "\n",
    "shuffle(labels)\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0de6d9-33b3-4534-bc76-e0fe504099ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    try:\n",
    "        print(\"Augumenting image:\",i,\"out of\", len(labels),\"completed\",round(i/len(labels)*100,2),\"%\", \"path\",label)\n",
    "        if df is None:\n",
    "            df = AugumentationPipeline(label,show = False)\n",
    "\n",
    "        else:\n",
    "            df2 = AugumentationPipeline(label,show = False)\n",
    "            df = pd.concat([df,df2])\n",
    "\n",
    "        df.to_csv(\"whole.csv\",header=False, index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e71c45-9c9d-4378-93bc-b4f9b76a0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c39fb-d65f-4188-a5e5-f064a79c8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"whole.csv\",header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d10896-27ee-4d7f-abc2-456dd3c6fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = AugumentationPipeline(label_paths[0],show = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707efe5-d4ba-4d80-b3c0-5b7a09ed650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.VerticalFlip(p=0.5),\n",
    "A.HorizontalFlip(p=0.5),\n",
    "\n",
    "transform = A.Compose([\n",
    "\n",
    "    #A.RandomCrop(width=int(w/i), height=int(h/i))\n",
    "\n",
    "],bbox_params = A.BboxParams(format='pascal_voc', min_visibility=0.77, label_fields=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b577f7-5fe1-4c69-89eb-1c087e60684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "4*4*4*80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9aa751-e519-4a66-a8e7-8ae012d517eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape,np.array(transformed_bboxes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd0149-4cb2-4f9c-a34a-c49c1f6c8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img                  = draw_labels(labels,img)\n",
    "transformed_draw_img = draw_labels(np.array(transformed_bboxes),transformed_img)\n",
    "\n",
    "f, axarr = plt.subplots(1,2,figsize=(32,14))\n",
    "axarr[0].axis('off')\n",
    "axarr[1].axis('off')\n",
    "axarr[0].set_title(\"Raw\")\n",
    "axarr[1].set_title(\"Transformed\")\n",
    "axarr[0].imshow(img[:,:,::-1])\n",
    "axarr[1].imshow(transformed_draw_img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210c920-c5b6-4532-b7b6-28fbdf2a5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pastaDrive = '/content/drive/MyDrive/images_16.02.22/augmentation'\n",
    "\n",
    "\n",
    "\n",
    "for image in images:\n",
    "    split = image.split(\"/\")\n",
    "    nomePasta = split[5]\n",
    "    nomeFoto = split[6]\n",
    "\n",
    "    bboxes = []\n",
    "\n",
    "\n",
    "    for row in trainRows:\n",
    "    if image == row[1]:\n",
    "        temp = []\n",
    "        temp.append(float(row[3]))\n",
    "        temp.append(float(row[4]))\n",
    "        temp.append(float(row[7]))\n",
    "        temp.append(float(row[8]))\n",
    "        bboxes.append(temp)\n",
    "\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "\n",
    "    transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.OneOf([\n",
    "        A.Blur(p=0.3),\n",
    "        A.MedianBlur(p=0.3),\n",
    "        A.MotionBlur(p=0.3),\n",
    "    ], p=0.8),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(p=1.0),\n",
    "    ], p=0.8),\n",
    "\n",
    "    # A.ISONoise(p=1.0),\n",
    "    # A.RandomRain(p=1.0, drop_length=27, blur_value=5, brightness_coefficient=0.7)\n",
    "    # A.RandomSunFlare(p=1.0)\n",
    "    # A.Perspective(p=1.0)\n",
    "    ],bbox_params=A.BboxParams(format='albumentations', label_fields=[]))\n",
    "\n",
    "\n",
    "    images_list = []\n",
    "    bboxes_list = []\n",
    "\n",
    "    for i in range(3):\n",
    "        transformed = transform(image=img, bboxes=bboxes)\n",
    "        transformed_img = transformed[\"image\"]\n",
    "        transformed_bboxes = transformed[\"bboxes\"]\n",
    "\n",
    "        images_list.append(transformed_img)\n",
    "        bboxes_list.append(transformed_bboxes)\n",
    "\n",
    "\n",
    "    photoCount = 1\n",
    "    j = 0\n",
    "    for imageT in images_list:\n",
    "        nomeFotoT = pastaDrive + '/' + nomePasta + '/' + nomeFoto[:-4] + '_T' + str(photoCount) + '.jpg'\n",
    "        cv2.imwrite(nomeFotoT, imageT)\n",
    "        height = imageT.shape[0]\n",
    "        width = imageT.shape[1]\n",
    "        for bboxes in bboxes_list[j]:  \n",
    "            x_min = bboxes[0]\n",
    "            y_min = bboxes[1]\n",
    "            x_max = bboxes[2]\n",
    "            y_max = bboxes[3]\n",
    "\n",
    "            ymin = int(max(1,(y_min * height)))\n",
    "            xmin = int(max(1,(x_min * width)))\n",
    "            ymax = int(min(height,(y_max * height)))\n",
    "            xmax = int(min(width,(x_max * width)))\n",
    "\n",
    "            data = [\"TRAIN\", nomeFotoT, 'log', x_min, y_min, x_max, y_min, x_max, y_max, x_min, y_max]\n",
    "\n",
    "            allRows.append(data)\n",
    "\n",
    "            cv2.rectangle(imageT, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "\n",
    "    photoCount += 1\n",
    "    j += 1\n",
    "    # cv2_imshow(imageT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e0bac-1334-47b7-add3-f4e6891bf8d9",
   "metadata": {},
   "source": [
    "SHUFFLE NO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538a52b-49fd-41d7-a542-b9a6df9f5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUniqueRows = []\n",
    "newRowsCount = []\n",
    "newRows = []\n",
    "\n",
    "\n",
    "for x in allRows:\n",
    "\n",
    "    newRowsCount.append(x)\n",
    "\n",
    "    linha = x[1]\n",
    "\n",
    "    if not newUniqueRows:\n",
    "        newUniqueRows.append(linha)\n",
    "\n",
    "    elif newUniqueRows[-1] != linha:\n",
    "        newUniqueRows.append(linha)\n",
    "\n",
    "\n",
    "#shuffle\n",
    "random.shuffle(newUniqueRows)\n",
    "\n",
    "\n",
    "for index, i in enumerate(newUniqueRows):\n",
    "    for j in newRowsCount:\n",
    "        if i == j[1]:\n",
    "            data = [j[0], j[1], j[2], j[3], j[4], j[5], j[6], j[7], j[8], j[9], j[10]]\n",
    "            newRows.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec788a-76c8-41b8-9cc2-bfdd08472d55",
   "metadata": {},
   "source": [
    "SALVA CSV COM TODAS AS BOUNDING BOXES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5fd80-86b7-4d8d-8e26-62f0143b1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/CSVs/Modelo5_T.csv', 'w', newline='') as f:\n",
    "\n",
    "    for data in newRows:\n",
    "\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff64995-df20-4c07-a4d2-83cdfd152ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
